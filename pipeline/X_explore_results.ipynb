{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import environ\n",
    "import sys\n",
    "import io\n",
    "from os.path import expanduser\n",
    "sys.path.append(\"../model/robosat_pink/\")\n",
    "\n",
    "from importlib import import_module\n",
    "import pkgutil\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "\n",
    "from re import match \n",
    "\n",
    "from numpy.random import randint\n",
    "import numpy as np\n",
    "\n",
    "import robosat_pink.losses\n",
    "import robosat_pink.models\n",
    "from robosat_pink.datasets import MultiSlippyMapTilesConcatenation\n",
    "from robosat_pink.tools.train import get_dataset_loaders\n",
    "from robosat_pink.config import load_config\n",
    "from robosat_pink.logs import Logs\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with Trained Model\n",
    "as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel = \"s3://planet-snowcover-models/05-02-19-checkpoints/checkpoint-00010-of-00010.pth\"\n",
    "modelConfig = '../s3-train.toml'\n",
    "\n",
    "S3_CHECKPOINT = False\n",
    "if trainedModel.startswith(\"s3://\"):\n",
    "    S3_CHECKPOINT = True\n",
    "    # load from s3 \n",
    "    trainedModel = trainedModel[5:]\n",
    "    sess = boto3.Session(profile_name='esip')\n",
    "    fs = s3fs.S3FileSystem(session=sess)\n",
    "    s3ckpt = s3fs.S3File(fs, trainedModel, 'rb')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(modelConfig)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "num_classes = len(config[\"classes\"])\n",
    "num_channels = 0\n",
    "for channel in config[\"channels\"]:\n",
    "    num_channels += len(channel[\"bands\"])\n",
    "pretrained = config[\"model\"][\"pretrained\"]\n",
    "encoder = config[\"model\"][\"encoder\"]\n",
    "\n",
    "models = [name for _, name, _ in pkgutil.iter_modules([os.path.dirname(robosat_pink.models.__file__)])]\n",
    "if config[\"model\"][\"name\"] not in [model for model in models]:\n",
    "    sys.exit(\"Unknown model, thoses available are {}\".format([model for model in models]))\n",
    "\n",
    "model_module = import_module(\"robosat_pink.models.{}\".format(config[\"model\"][\"name\"]))\n",
    "net = getattr(model_module, \"{}\".format(config[\"model\"][\"name\"].title()))(\n",
    "    num_classes=num_classes, num_channels=num_channels, encoder=encoder, pretrained=pretrained\n",
    ").to(device)\n",
    "\n",
    "net = torch.nn.DataParallel(net)\n",
    "optimizer = Adam(net.parameters(), lr=config[\"model\"][\"lr\"], weight_decay=config[\"model\"][\"decay\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_location(storage, _):\n",
    "    return storage.cuda() if torch.cuda.is_available() else storage.cpu()\n",
    "try: \n",
    "    if S3_CHECKPOINT:\n",
    "        with s3fs.S3File(fs, trainedModel, 'rb') as C:\n",
    "            state = torch.load(io.BytesIO(C.read()), map_location = map_location)\n",
    "    else: \n",
    "        state = torch.load(trainedModel, map_location= map_location)\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    net.load_state_dict(state['state_dict'])\n",
    "    net.to(device)\n",
    "except FileNotFoundError as f:\n",
    "    print(\"{} checkpoint not found.\".format(CHECKPOINT))\n",
    "\n",
    "losses = [name for _, name, _ in pkgutil.iter_modules([os.path.dirname(robosat_pink.losses.__file__)])]\n",
    "if config[\"model\"][\"loss\"] not in [loss for loss in losses]:\n",
    "    sys.exit(\"Unknown loss, thoses available are {}\".format([loss for loss in losses]))\n",
    "\n",
    "loss_module = import_module(\"robosat_pink.losses.{}\".format(config[\"model\"][\"loss\"]))\n",
    "criterion = getattr(loss_module, \"{}\".format(config[\"model\"][\"loss\"].title()))().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for imagery...(planet-snowcover-imagery/(.*)_AnalyticMS_SR_clip_tiled)\n",
      "candidates:\n",
      "['planet-snowcover-imagery/20180601_181447_0f32_3B_AnalyticMS_DN_udm_clip.tif', 'planet-snowcover-imagery/20180601_181447_0f32_3B_AnalyticMS_SR_clip.tif', 'planet-snowcover-imagery/20180601_181447_0f32_3B_AnalyticMS_metadata_clip.xml', 'planet-snowcover-imagery/20180601_181447_0f32_metadata.json', 'planet-snowcover-imagery/20180601_181448_0f32_3B_AnalyticMS_DN_udm_clip.tif', 'planet-snowcover-imagery/20180601_181448_0f32_3B_AnalyticMS_SR_clip.tif', 'planet-snowcover-imagery/20180601_181448_0f32_3B_AnalyticMS_metadata_clip.xml', 'planet-snowcover-imagery/20180601_181448_0f32_metadata.json', 'planet-snowcover-imagery/20180601_181449_0f32_3B_AnalyticMS_DN_udm_clip.tif', 'planet-snowcover-imagery/20180601_181449_0f32_3B_AnalyticMS_SR_clip_scaled.tif', 'planet-snowcover-imagery/20180601_181449_0f32_3B_AnalyticMS_metadata_clip.xml', 'planet-snowcover-imagery/20180601_181449_0f32_metadata.json', 'planet-snowcover-imagery/20180601_181450_0f32_3B_AnalyticMS_DN_udm_clip.tif', 'planet-snowcover-imagery/20180601_181450_0f32_3B_AnalyticMS_SR_clip.tif', 'planet-snowcover-imagery/20180601_181450_0f32_3B_AnalyticMS_metadata_clip.xml', 'planet-snowcover-imagery/20180601_181450_0f32_metadata.json', 'planet-snowcover-imagery/20180601_181451_0f32_3B_AnalyticMS_DN_udm_clip.tif', 'planet-snowcover-imagery/20180601_181451_0f32_3B_AnalyticMS_SR_clip.tif', 'planet-snowcover-imagery/20180601_181451_0f32_3B_AnalyticMS_metadata_clip.xml', 'planet-snowcover-imagery/20180601_181451_0f32_metadata.json', 'planet-snowcover-imagery/manifest.json', 'planet-snowcover-imagery/20180601_181447_0f32_3B_AnalyticMS_SR_clip_tiled', 'planet-snowcover-imagery/20180601_181448_0f32_3B_AnalyticMS_SR_clip_tiled', 'planet-snowcover-imagery/20180601_181450_0f32_3B_AnalyticMS_SR_clip_tiled', 'planet-snowcover-imagery/20180601_181451_0f32_3B_AnalyticMS_SR_clip_tiled', 'planet-snowcover-imagery/PSScene4Band_20170129_180054_0e0f_analytic_sr', 'planet-snowcover-imagery/planet-orders']\n",
      "result:\n",
      "['planet-snowcover-imagery/20180601_181447_0f32_3B_AnalyticMS_SR_clip_tiled', 'planet-snowcover-imagery/20180601_181448_0f32_3B_AnalyticMS_SR_clip_tiled', 'planet-snowcover-imagery/20180601_181450_0f32_3B_AnalyticMS_SR_clip_tiled', 'planet-snowcover-imagery/20180601_181451_0f32_3B_AnalyticMS_SR_clip_tiled']\n",
      "Searching for mask...(planet-snowcover-snow/ASO_3M_SD_USCASJ_20180601_tiles_02$)\n",
      "candidates:\n",
      "['planet-snowcover-snow/ASO_3M_SD_USCAJW_20180423.tif', 'planet-snowcover-snow/ASO_3M_SD_USCAJW_20180423', 'planet-snowcover-snow/ASO_3M_SD_USCASJ_20180601', 'planet-snowcover-snow/ASO_3M_SD_USCASJ_20180601_tiles', 'planet-snowcover-snow/ASO_3M_SD_USCASJ_20180601_tiles_02']\n",
      "result:\n",
      "['planet-snowcover-snow/ASO_3M_SD_USCASJ_20180601_tiles_02']\n",
      "Merging tilesets...\n"
     ]
    }
   ],
   "source": [
    "fs = s3fs.S3FileSystem(session = boto3.Session(profile_name = config['dataset']['aws_profile']))\n",
    "\n",
    "imagery_searchpath = config['dataset']['image_bucket']  + '/' +  config['dataset']['imagery_directory_regex']\n",
    "print(\"Searching for imagery...({})\".format(imagery_searchpath))\n",
    "imagery_candidates = fs.ls(config['dataset']['image_bucket'])\n",
    "print(\"candidates:\")\n",
    "print(imagery_candidates)\n",
    "imagery_locs = [c for c in imagery_candidates if match(imagery_searchpath, c)]\n",
    "print(\"result:\")\n",
    "print(imagery_locs)\n",
    "\n",
    "mask_searchpath = config['dataset']['mask_bucket'] + '/' +  config['dataset']['mask_directory_regex']\n",
    "print(\"Searching for mask...({})\".format(mask_searchpath))\n",
    "mask_candidates = fs.ls(config['dataset']['mask_bucket'])\n",
    "print(\"candidates:\")\n",
    "print(mask_candidates)\n",
    "mask_locs = [c for c in mask_candidates if match(mask_searchpath, c)]\n",
    "print(\"result:\")\n",
    "print(mask_locs)\n",
    "\n",
    "assert(len(mask_locs) > 0 and len(imagery_locs) > 0)\n",
    "\n",
    "print(\"Merging tilesets...\")\n",
    "\n",
    "allTiles = MultiSlippyMapTilesConcatenation(imagery_locs, mask_locs, aws_profile = config['dataset']['aws_profile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 8\n",
    "images, masks, tiles = [], [], []\n",
    "idxs = randint(0, len(allTiles), size=limit)\n",
    "for i in idxs:\n",
    "    i, m, t = allTiles[i]\n",
    "    images.append(i)\n",
    "    masks.append(m)\n",
    "    tiles.append(t)\n",
    "\n",
    "imageTensor = torch.from_numpy(np.stack(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.stack(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    raw = net(imageTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3(image, mask, pred, tile, ax = None):\n",
    "#     fig.suptitle(tile)\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title(tile)\n",
    "    ax[1].imshow(mask)\n",
    "    ax[1].set_title(\"mask\")\n",
    "    ax[2].imshow(pred, cmap='cividis', vmin = 0, vmax = 1)\n",
    "    ax[2].set_title('prediction')\n",
    "    diff = ax[3].imshow((pred > 0) - mask, cmap='seismic')\n",
    "    mets = sklearn.metrics.precision_recall_fscore_support(np.round(mask.flatten()), \n",
    "                                                          (pred > 0).flatten(), average='binary')\n",
    "    print(pred > 0)\n",
    "    ax[3].set_title(mets)\n",
    "#     plt.colorbar(diff, ax = ax[3])\n",
    "    # NDSI = 1-4 / 1 + 4\n",
    "#    plt.colorbar(pred, ax  = ax[2], orientation='horizontal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(raw.shape[0], 4, figsize=(20, 50))\n",
    "for image in range(raw.shape[0]):\n",
    "    plot3(imageTensor[image, 3, :, :], masks[image, :, :],  (raw[image]).detach().numpy().squeeze()  , tiles[image], ax = ax[image])\n",
    "#    plot3(s[0][image, 3, :, :], s[1][image, :, :],  torch.nn.functional.softmax(raw[image].squeeze(), dim=0).data.cpu().numpy())\n",
    "\n",
    "plt.savefig(\"testout.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7723510743272676, 0.7569613856555377, 0.7645787956790532, None)\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.precision_recall_fscore_support(np.round(masks.flatten()), (raw > 0).flatten().numpy(), average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Area under the ROC curve : 0.872022\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(np.round(masks.flatten()), (raw > 0).flatten().numpy())\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "print(\"\\n Area under the ROC curve : %f\" % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
